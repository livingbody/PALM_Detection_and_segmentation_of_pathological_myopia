# ä¸€ã€é£æ¡¨å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰² 5æœˆç¬¬3åæ–¹æ¡ˆ

**æ­¤æ–¹æ¡ˆæ¥è‡ªå¤§ä½¬çš„åŸºçº¿ï¼ŒéåŸåˆ›ã€‚åŸºçº¿åœ°å€ï¼š[ https://aistudio.baidu.com/aistudio/projectdetail/1941312?channelType=0&channel=0](https://aistudio.baidu.com/aistudio/projectdetail/1941312?channelType=0&channel=0)**

**githubåœ°å€ï¼š[https://github.com/livingbody/PALM_Detection_and_segmentation_of_pathological_myopia](https://github.com/livingbody/PALM_Detection_and_segmentation_of_pathological_myopia)**

**aistudioåœ°å€ï¼š[ https://aistudio.baidu.com/aistudio/projectdetail/1977014](https://aistudio.baidu.com/aistudio/projectdetail/1977014)**

æœ¬äººæœ‰å¹¸è·å¾—ç¬¬ä¸‰åã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/dc80241244184520aeb6a0b9d10ea3fc605f5563aba94ec7b1c92e793da6d56d)


## 1.**èµ›é¢˜ç®€è¿°**

	PALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²å¸¸è§„èµ›çš„é‡ç‚¹æ˜¯ç ”ç©¶å’Œå‘å±•ä¸ç—…ç†æ€§è¿‘è§†è¯Šæ–­å’Œæ‚£è€…çœ¼åº•ç…§ç‰‡ç—…å˜åˆ†å‰²ç›¸å…³çš„ç®—æ³•ã€‚è¯¥å¸¸è§„èµ›çš„ç›®æ ‡æ˜¯è¯„ä¼°å’Œæ¯”è¾ƒåœ¨ä¸€ä¸ªå¸¸è§çš„è§†ç½‘è†œçœ¼åº•å›¾åƒæ•°æ®é›†ä¸Šæ£€æµ‹ç—…ç†æ€§è¿‘è§†çš„è‡ªåŠ¨ç®—æ³•ã€‚å…·ä½“ä»»åŠ¡ä¸ºï¼šæ£€æµ‹çœ¼åº•å›¾åƒæ˜¯å¦å‡ºç°è§†ç½‘è†œèç¼©ç—…å˜å’Œè„±ç¦»ç—…å˜ï¼Œè‹¥æœ‰ï¼Œéœ€è¦å®ç°ç—…å˜åŒºåŸŸçš„åˆ†å‰²ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/bcb4c79dd34242e0bd83db8ea8062d7fa6a12a59999c44f09a73c9298a45fae3)
    
    
## 2.**æ•°æ®åŸºæœ¬æ ‡ç­¾**

	èç¼©ç—…å˜åˆ†å‰²é‡‘æ ‡å‡†ï¼šèç¼©åŒºåŸŸï¼š0ï¼›èƒŒæ™¯ï¼š255ï¼›
	è„±ç¦»ç—…å˜åˆ†å‰²é‡‘æ ‡å‡†ï¼šè„±ç¦»åŒºåŸŸï¼š0ï¼›èƒŒæ™¯ï¼š255ã€‚

## 3.**è®­ç»ƒæ•°æ®é›†**
æ–‡ä»¶åç§°ï¼šTrain

Trainé‡Œæœ‰ä¸¤ä¸ªæ–‡ä»¶å¤¹ï¼Œä¸€ä¸ªæ˜¯fundus_imagesï¼Œä¸€ä¸ªæ˜¯Lesion_Masksã€‚

* fundus_imagesæ–‡ä»¶å¤¹å†…åŒ…å«**800**å¼ çœ¼åº•å½©ç…§ï¼Œåˆ†è¾¨ç‡ä¸º1444Ã—1444ï¼Œæˆ–2124Ã—2056ã€‚å‘½åå½¢å¦‚H0001.jpgã€N0001.jpgã€P0001.jpgå’ŒV0001.jpgã€‚

* Lesion_Masksæ–‡ä»¶å¤¹å†…åŒ…å«ä¸¤ä¸ªæ–‡ä»¶å¤¹ï¼š**Atrophy**å’Œ**Detachment**ï¼Œå…¶ä¸­ï¼ŒAtrophyæ–‡ä»¶å¤¹åŒ…å«fundus_imagesé‡Œçœ¼åº•å½©ç…§çš„èç¼©ç—…å˜åŒºåŸŸåˆ†å‰²é‡‘æ ‡å‡†ï¼Œå¤§å°ä¸å¯¹åº”çš„çœ¼åº•å½©ç…§ä¸€è‡´ã€‚å‘½åå‰ç¼€ä¸å¯¹åº”çœ¼åº•å›¾åƒä¸€è‡´ï¼Œåç¼€ä¸ºbmpã€‚åŒç†ï¼ŒDetachmentæ–‡ä»¶å¤¹åŒ…å«fundus_imagesé‡Œçœ¼åº•å½©ç…§çš„è„±ç¦»ç—…å˜åŒºåŸŸåˆ†å‰²é‡‘æ ‡å‡†ï¼Œå¤§å°ä¸å¯¹åº”çš„çœ¼åº•å½©ç…§ä¸€è‡´ï¼Œå‘½åå‰ç¼€ä¸å¯¹åº”çœ¼åº•å›¾åƒä¸€è‡´ï¼Œåç¼€ä¸ºbmpã€‚**è¯·æ³¨æ„ï¼Œè‹¥Lesion_Masksä¸­æ— æŸå¼ çœ¼åº•å›¾åƒçš„ç—…ç¶åˆ†å‰²ç»“æœï¼Œè¯´æ˜è¯¥å›¾åƒä¸­ä¸åŒ…å«å¯¹åº”çš„ç—…ç¶åŒºåŸŸ**ã€‚

## 4.**æµ‹è¯•æ•°æ®é›†**

æ–‡ä»¶åç§°ï¼šPALM-Testing400-Images.zip

å‹ç¼©åŒ…é‡ŒåŒ…å«400å¼ çœ¼åº•å½©ç…§ï¼Œå‘½åå½¢å¦‚T0001.jpgã€‚


# äºŒã€æ–¹æ¡ˆç®€ä»‹

## 1.è§£å‹æ•°æ®ä¸æ•°æ®åˆ’åˆ†

    -- # è§£å‹æ•°æ®é›†
    
    -- !unzip -oq /home/aistudio/data/data85135/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰².zip -d PaddleSeg/data
    
    -- # åˆ’åˆ†æ•°æ®
    
    -- !python utils/dataset_splited.py

## 2.æ•°æ®æ ‡ç­¾é¢„å¤„ç†

    -- # è½¬æ¢æ ‡ç­¾
    
    -- !python utils/dataset_pretrans.py
    
    * åŸåˆ†ç±»ä¸º1åˆ†ç±»é—®é¢˜ï¼Œä¸ºäº†é—®é¢˜ç ”ç©¶çš„å……åˆ†æ€§å’Œæ›´å¤§ç¨‹åº¦ä¸Šåˆ©ç”¨å¤šåˆ†ç±»é—´çš„ç±»åˆ«ç«äº‰å¯¹åˆ†ç±»ç»“æ„æœ‰ä¸€ä¸ªæ›´å¥½çš„æŒ‡å¯¼
    
    * äºŒåˆ†ç±»é—®é¢˜æè¿°ï¼ŒåŸæ ‡ç­¾ä¸º0ä¸å˜ï¼Œå°†255æ— æ•ˆå€¼è½¬æ¢ä¸º1å€¼
    
    * åæœŸæäº¤å‰ä¼šåå¤„ç†ï¼Œæ¶ˆå»1å€¼ï¼Œæ¢å›èµ›é¢˜éœ€è¦çš„255å€¼

## 3.åˆ©ç”¨PaddleSegå¥—ä»¶åŠ é€Ÿèµ›é¢˜å¼€å‘ä¸æµ‹è¯•: ä½¿ç”¨å¥—ä»¶configä¸­çš„æ¨¡å‹ymlè¿›è¡Œå¿«é€Ÿé«˜æ•ˆçš„å®éªŒå¼€å‘â€”â€”æ³¨æ„æ•°æ®é›†ymlçš„é…ç½®

## 4. å®ç°è®­ç»ƒæµç¨‹

## 5.å®ç°é¢„æµ‹æµç¨‹

## 6. å®Œæˆæäº¤ç»“æœ -- åŸºçº¿æ–¹æ¡ˆä¸º0.67+çš„å¾—åˆ†(D_iter:500, A_iter:2000)ï¼Œå¯ä»è®­ç»ƒè¿­ä»£æ¬¡æ•°ã€æŸå¤±å‡½æ•°ã€æ¨¡å‹å…¥æ‰‹

    -- # æäº¤ç»“æœåå¤„ç†
    
    -- utils/post_process.py


# ä¸‰ã€æ•°æ®å¤„ç†

## 1. å…ˆè§£å‹éœ€è¦çš„PadleSegå¥—ä»¶


```python
# è§£å‹PaddleSegå‹ç¼©åŒ…
!unzip -oq data/data88946/PaddleSeg.zip -d /home/aistudio/
# ä¿®æ”¹æ–‡ä»¶å
!mv PaddleSeg-release-v2.0 PaddleSeg
```

ä¸Šä¸€æ­¥mvï¼Œå¯ä»¥å°†PaddleSegåŠ å‹åçš„æ–‡ä»¶ç›®å½•æ”¹æˆPaddleSeg
>PaddleSegä¸‹è½½è‡³githubçš„release2.0ç‰ˆæœ¬ï¼Œä¸ºäº†æ–¹ä¾¿å¤§å®¶ä½¿ç”¨ï¼Œå·²æ·»åŠ åœ¨äº†æ•°æ®é›†ä¸­ä¾›å¤§å®¶ä½¿ç”¨

## 2.æ¸…ç†dataå¹¶æ·»åŠ æ•°æ®


```python
# åˆ é™¤dataç›®å½• â€”â€” ç”¨äºæ•°æ®åˆ’åˆ†æ—¶ï¼Œäº§ç”Ÿäº†æ„æ–™ä¹‹å¤–çš„æ•°æ®æ‰©å……æ—¶çš„æ•°æ®é‡ç½®
%cd /home/aistudio/
!rm -rf PaddleSeg/data
# è§£å‹æ•°æ®é›†åˆ°PaddleSegç›®å½•ä¸‹çš„dataæ–‡ä»¶å¤¹
!unzip -oq /home/aistudio/data/data85135/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰².zip -d PaddleSeg/data
```

    /home/aistudio


## 3.æŸ¥çœ‹æ•°æ®


```python
# æŸ¥çœ‹æ•°æ®é›†æ–‡ä»¶çš„æ ‘å½¢ç»“æ„
!tree -d PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²
```

    PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²
    â”œâ”€â”€ PALM-Testing400-Images
    â””â”€â”€ Train
        â”œâ”€â”€ fundus_image
        â””â”€â”€ Lesion_Masks
            â”œâ”€â”€ Atrophy
            â””â”€â”€ Detachment
    
    6 directories


## 4.æ¯”èµ›æ•°æ®é›†æƒ…å†µ

PALM-Testing400-Images : æµ‹è¯•æ•°æ®é›†æ–‡ä»¶å¤¹

Train : è®­ç»ƒæ•°æ®é›†æ–‡ä»¶å¤¹

* Lesion_Masks ; æ ‡æ³¨å›¾ç‰‡

	-- Detachment è§†ç½‘è†œè„±è½æ ‡æ³¨ -- æ ·æœ¬è¾ƒå°‘ï¼Œå­˜åœ¨åŒæ—¶èç¼©çš„æ ·æœ¬
  
   -- Atrophy èç¼©æ ‡æ³¨
  
* fundus_image : åŸå§‹å›¾ç‰‡

> æ³¨æ„æ²¡æœ‰éªŒè¯æ•°æ®é›†ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªç®€å•çš„åˆ’åˆ†ç¨‹åºï¼Œåˆ’åˆ†æ¯”ä¾‹ä¸º0.7

> utils/dataset_splited.py

é€šè¿‡PILçš„Imageè¯»å–å›¾ç‰‡æŸ¥çœ‹ä»¥ä¸‹åŸæ•°æ®ä¸Labelæ ‡æ³¨æƒ…å†µ


```python
from PIL import Image
import numpy as np
# è¯»å–å›¾ç‰‡
png_img = Image.open('PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²/Train/fundus_image/H0003.jpg')
png_img  # å±•ç¤ºçœŸå®å›¾ç‰‡
```


```python
bmp_img = Image.open('PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²/Train/Lesion_Masks/Atrophy/H0003.bmp')
bmp_img   # å±•ç¤ºèç¼©æ ‡æ³¨å›¾ç‰‡
```


```python
bmp_img = Image.open('PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²/Train/Lesion_Masks/Detachment/P0053.bmp')
bmp_img   # å±•ç¤ºè„±è½æ ‡æ³¨å›¾ç‰‡
```

## 5.åˆ’åˆ†æ•°æ®é›†ä¸æ•°æ®é¢„å¤„ç½®

å½“å‰åˆ’åˆ†æ¯”ä¾‹ä¸º0.8â€”â€”å¯åœ¨utilsæ–‡ä»¶å¤¹ä¸‹çš„dataset_splited.pyä¿®æ”¹**train_percent**ä¸ºå…¶å®ƒå€¼

æ•°æ®é¢„å¤„ç½®-å¯åœ¨utilsæ–‡ä»¶å¤¹ä¸‹çš„dataset_pretrans.pyä¸­æŸ¥çœ‹ç›¸å…³ä»£ç --å®ç°å°†255è½¬åŒ–ä¸º1ï¼ŒåŸé—®é¢˜å˜äºŒåˆ†ç±»é—®é¢˜

> æ³¨æ„ï¼šå½“å‰æ•°æ®å¤„ç†ä¸­ï¼Œå­˜åœ¨å¯¹æ•°æ®è¿›è¡Œæ‰©å……ï¼Œå› æ­¤å½“å‰ç¨‹åºè¿è¡Œä¸€æ¬¡ä¹‹åä¼šä½¿å¾—åŸåˆ†ç±»æ•°æ®æ•°ç›®å¢åŠ â€”â€”(æ‰©å¢ä¸å®œè¿‡å¤§ï¼Œå¦åˆ™åˆ’åˆ†æ•°æ®è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯æ—¶ä¼šå‡ºç°åå·®é—®é¢˜)

> ä»…å¯è¿è¡Œä¸€æ¬¡ï¼Œå¤šæ¬¡è¿è¡Œä¼šå¯¼è‡´å¡«å……æ•°é‡è¿‡å¤šï¼Œè¿™æ˜¯æºç ä¸­æ‰©å……æœºåˆ¶å†³å®šçš„(ç›´æ¥æ‰©å……åˆ°æºæ–‡ä»¶å¤¹ä¸­ï¼Œæ‰€ä»¥ä¸‹ä¸€æ¬¡åˆ’åˆ†çš„æ—¶å€™å°±ä¼šé»˜è®¤æŠŠæºæ–‡ä»¶ä¸­æ‰€æœ‰çš„æ–‡ä»¶è¯»å–)

> æ„Ÿå…´è¶£å¯å‰å¾€æŸ¥çœ‹dataset_splited.pyçš„æ•°æ®æ‰©å……åŒº

```
# dataset_splited.py
import os
import random
import shutil
from tqdm import tqdm
from PIL import Image
import time
import numpy as np

random.seed(2021)

print('â€”â€”â€”â€”å¼€å§‹æ•°æ®æ¸…æ´—åˆ’åˆ†â€”â€”â€”â€”')

records_png = []
records_a_bmp = []   # è®°å½•èç¼©æ ‡æ³¨
records_d_bmp = []   # è®°å½•è„±è½æ ‡æ³¨
records_test = []

png_root = 'PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²/Train/fundus_image'
bmp_root = 'PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²/Train/Lesion_Masks'
test_root = 'PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²/PALM-Testing400-Images'

bmp_sub_root1 = 'Detachment'    # è„±è½æ ‡æ³¨
bmp_sub_root2 = 'Atrophy'       # èç¼©æ ‡æ³¨

# ç­›é€‰åŸå§‹è®­ç»ƒæ•°æ®ä¸­çš„jpgæ–‡ä»¶
for _, _, files in os.walk(png_root):
    for i in files:
        if i[-3:] == 'jpg':
            records_png.append(i)

# ç­›é€‰åŸå§‹è®­ç»ƒæ•°æ®ä¸­çš„bmpæ–‡ä»¶
for _, _, files in os.walk(os.path.join(bmp_root, bmp_sub_root1)):
    for i in files:
        if i[-3:] == 'bmp':
            records_d_bmp.append(i)
for _, _, files in os.walk(os.path.join(bmp_root, bmp_sub_root2)):
    for i in files:
        if i[-3:] == 'bmp':
            records_a_bmp.append(i)

# ç­›é€‰åŸå§‹æµ‹è¯•æ•°æ®ä¸­çš„jpgæ–‡ä»¶
for _, _, files in os.walk(test_root):
    for i in files:
        if i[-3:] == 'jpg':
            records_test.append(i)

print('BMPæ ‡æ³¨æ•°æ®: Detachment: {0}å¼  \t Atrophy: {1}å¼ '.format(len(records_d_bmp), len(records_a_bmp)))

# æ˜ç¡®ä¿å­˜ç›®å½•æ–¹å¼
save_png_path_D = os.path.join('PaddleSeg/data', bmp_sub_root1)
save_png_path_A = os.path.join('PaddleSeg/data', bmp_sub_root2)
image_path = 'Image'
label_path = 'Label'
test_path = 'Test'

print('â€”â€”â€”â€” å¼€å§‹æ„å»ºæ•°æ®ç›®å½• â€”â€”â€”â€”')
# ç”ŸæˆDetachmentè®­ç»ƒå¯¹åº”çš„ç›®å½•
if os.path.exists(os.path.join(save_png_path_D, image_path)):
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_D, image_path)))
else:
    os.makedirs(os.path.join(save_png_path_D, image_path))
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_D, image_path)))
if os.path.exists(os.path.join(save_png_path_D, label_path)):
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_D, label_path)))
else:
    os.makedirs(os.path.join(save_png_path_D, label_path))
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_D, label_path)))
if os.path.exists(os.path.join(save_png_path_D, test_path)):
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_D, test_path)))
else:
    os.makedirs(os.path.join(save_png_path_D, test_path))
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_D, test_path)))
# ç”ŸæˆAtrophyè®­ç»ƒå¯¹åº”çš„ç›®å½•
if os.path.exists(os.path.join(save_png_path_A, image_path)):
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_A, image_path)))
else:
    os.makedirs(os.path.join(save_png_path_A, image_path))
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_A, image_path)))
if os.path.exists(os.path.join(save_png_path_A, label_path)):
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_A, label_path)))
else:
    os.makedirs(os.path.join(save_png_path_A, label_path))
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_A, label_path)))
if os.path.exists(os.path.join(save_png_path_A, test_path)):
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_A, test_path)))
else:
    os.makedirs(os.path.join(save_png_path_A, test_path))
    print('The Dir Has Create: {0} '.format(os.path.join(save_png_path_A, test_path)))

#############################################################################################################################################
#########################################   å¦‚æœä¸éœ€è¦æ•°æ®æ‰©å……ï¼Œå¯ä»¥æ³¨é‡Šä»¥ä¸‹éƒ¨åˆ†ä»£ç (æ‰©å……åˆ°åŸæ¥çš„æ•°æ®ä¸­)     #####################################
#############################################################################################################################################
print('â€”â€”â€”â€”å¼€å§‹é’ˆå¯¹ç±»åˆ«Detachmentè¿›è¡Œæ•°æ®æ‰©å……({0}å¼ )â€”â€”â€”â€”'.format(len(records_d_bmp)//6))

# åˆ©ç”¨é‚£äº›æ²¡æœ‰é—®é¢˜çš„jpgçœŸå®æ•°æ®ç”Ÿæˆå…¨255çš„æ ‡æ³¨å›¾
# ç„¶åæ‰©å……åˆ°å°‘ç±»åˆ«ä¸­è¿›è¡Œå¾®é‡æ•°æ®è¡¥å……
last_lens = len(records_d_bmp)        # æ•°æ®æ‰©å¢å‰çš„æ•°æ®é•¿åº¦
can_add_img = []                      # æœå¯»å¯ä»¥è¢«æ·»åŠ çš„å›¾ç‰‡
to_add_length = len(records_d_bmp)//6    # æ‰©å¢æ•°é‡

add_tq = tqdm(records_png)
add_tq.set_description("Processing Train-{0} Split".format(bmp_sub_root1))
for i in add_tq:
    if (i[:-4] + '.bmp') not in records_d_bmp and (i[:-4] + '.bmp') not in records_a_bmp:
        img_ = Image.open(os.path.join(png_root, i))
        img_ = img_.convert('L')
        img_ = np.asarray(img_).copy()
        img_[:] = 255
        img_ = Image.fromarray(img_)
        img_.save(os.path.join(os.path.join(bmp_root, bmp_sub_root1), i[:-4] + '.bmp'))  # ä¿å­˜åˆ°å¯¹åº”å°‘ç±»æ¯”åŸæ ‡æ³¨æ–‡ä»¶å¤¹ä¸­
        can_add_img.append(i[:-4] + '.bmp')         # å¯ä»¥è¢«æ·»åŠ åˆ°å°‘æ•°ç±»åˆ«ä¸­çš„å›¾ç‰‡
random.shuffle(can_add_img)
records_d_bmp = records_d_bmp + can_add_img[:to_add_length]
random.shuffle(records_d_bmp)
print('å®é™…æ‰©å……: {0} å¼ , ç°ç±»åˆ« {1} æ‹¥æœ‰æ•°æ®: {2} ä»½'.format(len(can_add_img), bmp_sub_root1, len(records_d_bmp)))


print('â€”â€”â€”â€”å¼€å§‹é’ˆå¯¹ç±»åˆ«Atrophyè¿›è¡Œæ•°æ®æ‰©å……({0}å¼ )â€”â€”â€”â€”'.format(len(records_a_bmp)//18))
# åˆ©ç”¨é‚£äº›æ²¡æœ‰é—®é¢˜çš„jpgçœŸå®æ•°æ®ç”Ÿæˆå…¨255çš„æ ‡æ³¨å›¾
# ç„¶åæ‰©å……åˆ°å°‘ç±»åˆ«ä¸­è¿›è¡Œå¾®é‡æ•°æ®è¡¥å……
last_lens = len(records_d_bmp)        # æ•°æ®æ‰©å¢å‰çš„æ•°æ®é•¿åº¦
can_add_img = []                      # æœå¯»å¯ä»¥è¢«æ·»åŠ çš„å›¾ç‰‡
to_add_length = len(records_a_bmp)//18    # æ‰©å¢æ•°é‡

add_tq = tqdm(records_png)
add_tq.set_description("Processing Train-{0} Split".format(bmp_sub_root2))
for i in add_tq:  
    if (i[:-4] + '.bmp') not in records_a_bmp and (i[:-4] + '.bmp') not in records_d_bmp:
        img_ = Image.open(os.path.join(png_root, i))
        img_ = img_.convert('L')
        img_ = np.asarray(img_).copy()
        img_[:] = 255
        img_ = Image.fromarray(img_)
        img_.save(os.path.join(os.path.join(bmp_root, bmp_sub_root2), i[:-4] + '.bmp'))  # ä¿å­˜åˆ°å¯¹åº”å°‘ç±»æ¯”åŸæ ‡æ³¨æ–‡ä»¶å¤¹ä¸­
        can_add_img.append(i[:-4] + '.bmp')         # å¯ä»¥è¢«æ·»åŠ åˆ°å°‘æ•°ç±»åˆ«ä¸­çš„å›¾ç‰‡
random.shuffle(can_add_img)
records_a_bmp = records_a_bmp + can_add_img[:to_add_length]
random.shuffle(records_a_bmp)
print('å®é™…æ‰©å……: {0} å¼ , ç°ç±»åˆ« {1} æ‹¥æœ‰æ•°æ®: {2} ä»½'.format(len(can_add_img), bmp_sub_root2, len(records_a_bmp)))

#############################################################################################################################################
#########################################                å¦‚æœä¸éœ€è¦æ•°æ®æ‰©å……ï¼Œå¯ä»¥æ³¨é‡Šä»¥ä¸Šéƒ¨åˆ†ä»£ç           #####################################
#############################################################################################################################################


def Split_Train_And_Eval_Data(t_per, c_kind):
    '''æ ¹æ®ç±»åˆ«åˆ’åˆ†è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ•°æ®
        t_per: è®­ç»ƒé›†åˆ’åˆ†æ¯”ä¾‹
        c_kind: å½“å‰åˆ’åˆ†ç±»åˆ«
    '''
    assert c_kind in ['Detachment', 'Atrophy'], \
        'Only allowed the 2 kind class: [Detachment, Atrophy].'

    if c_kind == 'Detachment':   # ä¸åŒç±»åˆ«çš„å­˜æ”¾åŒºåŸŸ
        save_png_path = save_png_path_D
        records = records_d_bmp
    elif c_kind == 'Atrophy':
        save_png_path = save_png_path_A
        records = records_a_bmp

    train_percent = t_per  # åˆ’åˆ†æ¯”ä¾‹
    print('The Split Params: train_percent={0:.2f}'.format(train_percent))

    train_records = records[:int(train_percent*len(records))]      # è®­ç»ƒéªŒè¯çš„åˆ’åˆ†
    eval_records = records[int(train_percent*len(records)):]

    train_txt_path = os.path.join(save_png_path, 'train_list.txt')
    with open(train_txt_path, 'w') as f:
        train_tq = tqdm(train_records)
        train_tq.set_description("Processing Train-{0} Split".format(c_kind))
        for bmp_ in train_tq:                                                                        # å†™å…¥å¹¶ä¿å­˜è®­ç»ƒå›¾ç‰‡
            png_ = bmp_[:-4]+'.jpg'
            old_png_path = os.path.join(png_root, png_)
            old_bmp_path = os.path.join(os.path.join(bmp_root, c_kind), bmp_)
            new_png_path = os.path.join(os.path.join(save_png_path, image_path), png_)
            new_bmp_path = os.path.join(os.path.join(save_png_path, label_path), bmp_)
            shutil.copyfile(old_png_path, new_png_path) 
            shutil.copyfile(old_bmp_path, new_bmp_path)
            f.write('{0} {1}\n'.format(os.path.join('Image', png_), os.path.join('Label', bmp_)))

    eval_txt_path = os.path.join(save_png_path, 'val_list.txt')
    with open(eval_txt_path, 'w') as f:                                                              # å†™å…¥å¹¶ä¿å­˜éªŒè¯å›¾ç‰‡
        eval_tq = tqdm(eval_records)
        eval_tq.set_description("Processing Eval-{0} Split".format(c_kind))
        for bmp_ in eval_tq:
            png_ = bmp_[:-4]+'.jpg'
            old_png_path = os.path.join(png_root, png_)
            old_bmp_path = os.path.join(os.path.join(bmp_root, c_kind), bmp_)
            new_png_path = os.path.join(os.path.join(save_png_path, image_path), png_)
            new_bmp_path = os.path.join(os.path.join(save_png_path, label_path), bmp_)
            shutil.copyfile(old_png_path, new_png_path) 
            shutil.copyfile(old_bmp_path, new_bmp_path)
            f.write('{0} {1}\n'.format(os.path.join('Image', png_), os.path.join('Label', bmp_)))
    
    test_txt_path = os.path.join(save_png_path, 'test_list.txt')              
    with open(test_txt_path, 'w') as f:                                                               # å†™å…¥å¹¶ä¿å­˜æµ‹è¯•å›¾ç‰‡
        test_tq = tqdm(records_test)
        test_tq.set_description("Processing Test-{0} Split".format(c_kind))
        for png_ in test_tq:
            old_png_path = os.path.join(test_root, png_)
            new_png_path = os.path.join(os.path.join(save_png_path, test_path), png_)
            shutil.copyfile(old_png_path, new_png_path) 
            f.write('{0}\n'.format(os.path.join('Test', png_)))

train_percent = 0.8  # åˆ’åˆ†æ¯”ä¾‹
print('â€”â€”å¼€å§‹åˆ’åˆ†Detachmentâ€”â€”')
Split_Train_And_Eval_Data(t_per=train_percent, c_kind=bmp_sub_root1)        # åˆ’åˆ†ç±»åˆ«1--Detachment
print('â€”â€”å¼€å§‹åˆ’åˆ†Atrophyâ€”â€”')
Split_Train_And_Eval_Data(t_per=train_percent, c_kind=bmp_sub_root2)        # åˆ’åˆ†ç±»åˆ«2--Atrophy

# å±•ç¤ºæ ‘å½¢ç»“æ„
os.system('tree -d PaddleSeg/data')
```


```
# dataset_pretrans.py

import PIL.Image as Image
from tqdm import tqdm
import numpy as np
import os
import time


print('\nâ€”â€”â€”â€”å¼€å§‹æ•°æ®é¢„å¤„ç†è½¬æ¢â€”â€”â€”â€”')
print('è½¬æ¢è¯´æ˜:')
print('\t 1. é»˜è®¤æ ‡ç­¾ä¸º255ä¸0ï¼Œä¸ºäº†è®­ç»ƒæ–¹ä¾¿ï¼Œå°†255è½¬æ¢ä¸º1ï¼Œå˜æˆ2åˆ†ç±»é—®é¢˜')
print('\t 2. æ–°æ ‡ç­¾0ä¸1ï¼Œé¢„æµ‹ç»“æŸè¿›è¡Œåå¤„ç†å³å¯å¾—åˆ°èµ›é¢˜éœ€è¦çš„ç»“æœ')


bmp_sub_root1 = 'Detachment'    # è„±è½æ ‡æ³¨
bmp_sub_root2 = 'Atrophy'       # èç¼©æ ‡æ³¨

data_root  = 'PaddleSeg/data'
label_path = 'Label'


def to_work_bmp(c_kind):

    assert c_kind in ['Detachment', 'Atrophy'], \
        'Only allowed the 2 kind class: [Detachment, Atrophy].'

    # ä¸åŒç±»åˆ«Labelå¯¹åº”çš„å­˜æ”¾ä½ç½®
    data_path = os.path.join(data_root, c_kind)
    data_path = os.path.join(data_path, label_path)

    for _, _, files in os.walk(data_path):
        for f in tqdm(files):
            img = Image.open(os.path.join(data_path, f))
            img = np.asarray(img).copy()
            img[img == 255] = 1
            img = Image.fromarray(img)
            img.save(os.path.join(data_path, f))


print('â€”â€”â€”â€”å¼€å§‹Detachmentçš„æ•°æ®é¢„å¤„ç½®â€”â€”â€”â€”')
time.sleep(0.2)

to_work_bmp(bmp_sub_root1)



print('â€”â€”â€”â€”å¼€å§‹Atrophyçš„æ•°æ®é¢„å¤„ç½®â€”â€”â€”â€”')
time.sleep(0.2)

to_work_bmp(bmp_sub_root2)
```


```python
# ä¿è¯è·¯å¾„ä¸ºåˆå§‹è·¯å¾„
%cd /home/aistudio

# åˆ’åˆ†æ•°æ®
!python utils/dataset_splited.py

# è½¬æ¢æ ‡ç­¾--é¢„å¤„ç½®
!python utils/dataset_pretrans.py
```

    Processing Train-Detachment Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:18<00:00, 44.03it/s]
    å®é™…æ‰©å……: 213 å¼ , ç°ç±»åˆ« Detachment æ‹¥æœ‰æ•°æ®: 21 ä»½
    â€”â€”â€”â€”å¼€å§‹é’ˆå¯¹ç±»åˆ«Atrophyè¿›è¡Œæ•°æ®æ‰©å……(32å¼ )â€”â€”â€”â€”
    Processing Train-Atrophy Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:18<00:00, 44.30it/s]
    å®é™…æ‰©å……: 210 å¼ , ç°ç±»åˆ« Atrophy æ‹¥æœ‰æ•°æ®: 614 ä»½
    â€”â€”å¼€å§‹åˆ’åˆ†Detachmentâ€”â€”
    The Split Params: train_percent=0.80
    Processing Train-Detachment Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 156.44it/s]
    Processing Eval-Detachment Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 153.25it/s]
    Processing Test-Detachment Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<00:00, 567.17it/s]
    â€”â€”å¼€å§‹åˆ’åˆ†Atrophyâ€”â€”
    The Split Params: train_percent=0.80
    Processing Train-Atrophy Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 491/491 [00:03<00:00, 161.61it/s]
    Processing Eval-Atrophy Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:00<00:00, 172.47it/s]
    Processing Test-Atrophy Split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<00:00, 594.46it/s]
    PaddleSeg/data
    â”œâ”€â”€ Atrophy
    â”‚Â Â  â”œâ”€â”€ Image
    â”‚Â Â  â”œâ”€â”€ Label
    â”‚Â Â  â””â”€â”€ Test
    â”œâ”€â”€ Detachment
    â”‚Â Â  â”œâ”€â”€ Image
    â”‚Â Â  â”œâ”€â”€ Label
    â”‚Â Â  â””â”€â”€ Test
    â”œâ”€â”€ __MACOSX
    â”‚Â Â  â””â”€â”€ å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²
    â”‚Â Â      â”œâ”€â”€ PALM-Testing400-Images
    â”‚Â Â      â””â”€â”€ Train
    â”‚Â Â          â”œâ”€â”€ fundus_image
    â”‚Â Â          â””â”€â”€ Lesion_Masks
    â”‚Â Â              â”œâ”€â”€ Atrophy
    â”‚Â Â              â””â”€â”€ Detachment
    â””â”€â”€ å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²
        â”œâ”€â”€ PALM-Testing400-Images
        â””â”€â”€ Train
            â”œâ”€â”€ fundus_image
            â””â”€â”€ Lesion_Masks
                â”œâ”€â”€ Atrophy
                â””â”€â”€ Detachment
    
    23 directories
    
    â€”â€”â€”â€”å¼€å§‹æ•°æ®é¢„å¤„ç†è½¬æ¢â€”â€”â€”â€”
    è½¬æ¢è¯´æ˜:
    	 1. é»˜è®¤æ ‡ç­¾ä¸º255ä¸0ï¼Œä¸ºäº†è®­ç»ƒæ–¹ä¾¿ï¼Œå°†255è½¬æ¢ä¸º1ï¼Œå˜æˆ2åˆ†ç±»é—®é¢˜
    	 2. æ–°æ ‡ç­¾0ä¸1ï¼Œé¢„æµ‹ç»“æŸè¿›è¡Œåå¤„ç†å³å¯å¾—åˆ°èµ›é¢˜éœ€è¦çš„ç»“æœ
    â€”â€”â€”â€”å¼€å§‹Detachmentçš„æ•°æ®é¢„å¤„ç½®â€”â€”â€”â€”
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 53.26it/s]
    â€”â€”â€”â€”å¼€å§‹Atrophyçš„æ•°æ®é¢„å¤„ç½®â€”â€”â€”â€”
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:10<00:00, 61.39it/s]


## 6.åˆ é™¤åŸæ•°æ®ç›®å½•


```python
# ç§»é™¤â€™å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²â€˜æ–‡ä»¶å¤¹
!rm -rf PaddleSeg/data/å¸¸è§„èµ›ï¼šPALMç—…ç†æ€§è¿‘è§†ç—…ç¶æ£€æµ‹ä¸åˆ†å‰²
!rm -rf PaddleSeg/data/__MACOSX 
```

# å››ã€é€‰æ‹©æ¯”èµ›æ¨¡å‹

åŸºçº¿æ¨¡å‹ä¸º:  é…ç½®ç•¥å¾®ä¿®æ”¹çš„`PaddleSeg/configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k.yml`

å…·ä½“é…ç½®åœ¨
	
	-- example/emanet_resnet50_os8_voc12aug_512x512_40k_Deta.yml
	* ç”¨äºåˆ†å‰²è„±è½æƒ…å†µ
	
	-- example/emanet_resnet50_os8_voc12aug_512x512_40k_Atro.yml
	* ç”¨äºåˆ†å‰²èç¼©æƒ…å†µ

è¯¦ç»†æ•°æ®é›†é…ç½®åœ¨

	-- example/pascal_voc2012_Deta.yml
	* ç”¨äºè®¾ç½®è„±è½æƒ…å†µæ•°æ®
	
	-- example/pascal_voc2012_Atro.yml
	* ç”¨äºè®¾ç½®èç¼©æƒ…å†µæ•°æ®


> é’ˆå¯¹ä¸åŒåˆ†å‰²ä»»åŠ¡é…ç½®ä¸åŒçš„åˆ†å‰²æ¨¡å‹ï¼Œä»¥é€‚é…ä¸åŒçš„ä»»åŠ¡é©±åŠ¨

## 1.é…ç½®_base_ä¸­å¯¹åº”çš„æ•°æ®é›†ä¸æ¨¡å‹

> å…·ä½“é…ç½®ä¿¡æ¯ï¼Œå¯ä»¥åœ¨`examples`æ–‡ä»¶å¤¹ä¸‹æŸ¥çœ‹ç›¸åº”`yml`æ–‡ä»¶ï¼Œæœ‰ç›¸åº”çš„æ³¨é‡Šã€‚

**ç®€è¦è¯´æ˜`example/pascal_voc2012_Deta.yml`ä¸­çš„é…ç½®è¦ç‚¹**ï¼Œä»¥æ–¹ä¾¿å¤§å®¶ä¿®æ”¹å…¶ä»–çš„æ•°æ®é›†ymlé€‚é…æ¨¡å‹è®­ç»ƒ

```yml
# è¯¥æ–‡ä»¶éœ€è¦è‡ªè¡Œç§»åŠ¨åˆ°PaddleSeg/configs/_base_ä¸‹, å¹¶ä¿®æ”¹æ¨¡å‹æ–‡ä»¶ä¸­çš„_base_è·¯å¾„(å»ºè®®)
# æˆ–è€…æ ¹æ®è¯¥æ–‡ä»¶ä¸­çš„train_datasetä¸val_datasetï¼Œå¯¹_base_ä¸‹ç›¸åº”çš„ymlè¿›è¡Œä¿®æ”¹

# æ‰¹å¤§å°   -- å¯é€šè¿‡è®­ç»ƒæ—¶åŠ¨æ€è°ƒæ•´
batch_size: 4
# è¿­ä»£æ¬¡æ•° -- å¯é€šè¿‡è®­ç»ƒæ—¶åŠ¨æ€è°ƒæ•´ 
iters: 40000

# è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½çš„æ–¹å¼
train_dataset:
  # è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½æ–¹å¼ï¼šDataset
  type: Dataset
  # æ•°æ®é›†ç›®å½•--å½“å‰é¡¹ç›®ä¸­ç±»åˆ«Detachmentçš„æ•°æ®éƒ½æ”¾åœ¨äº†è¿™é‡Œï¼šdata/Detachment
  # ä¸åŒç±»åˆ«çš„è®­ç»ƒï¼Œå¯ä»¥æ¢æˆä¸åŒçš„æ•°æ®æ ¹ç›®å½•
  # Atrophyç±»--å¯¹åº”data/Atrophy
  dataset_root: data/Detachment
  # è¯¥ç›®å½•ä¸‹åˆ’åˆ†æ•°æ®äº§ç”Ÿçš„txtï¼šdata/Detachment/train_list.txt
  train_path: data/Detachment/train_list.txt
  # ç±»åˆ«--å½“å‰å·²è½¬æ¢ä¸º2åˆ†ç±»é—®é¢˜
  num_classes: 2
  # é¢„å¤„ç†
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
    # è€ƒè™‘åˆ°å½“å‰æ•°æ®é›†æ­£ç¡®åˆ’åˆ†åŒºåŸŸè¾ƒå°ï¼ŒRandomPaddingCropæ˜¯å¦æœ‰å¿…è¦ä¸æ¸…æ¥šï¼Œå¯ä»¥è‡ªè¡Œå°è¯•
    # ä¸‹è¾¹æœ‰æä¾›Resizeå¤„ç†ç¼©æ”¾--é€‰1ç¼©æ”¾æ ‡å‡†å³å¯
    # - type: RandomPaddingCrop
    #   crop_size: [600, 600]
    - type: Resize
      target_size: [800, 800]
    - type: RandomHorizontalFlip
    - type: Normalize
  # æ•°æ®é›†åŠ è½½æ–¹å¼--æ³¨æ„è¦ä¸€ä¸€å¯¹åº”
  mode: train

val_dataset:
  type: Dataset
  dataset_root: data/Detachment
  # æ³¨æ„éªŒè¯æ•°æ®é›†çš„pathå’Œè®­ç»ƒæ•°æ®é›†pathçš„åŒºåˆ«
  val_path: data/Detachment/val_list.txt
  num_classes: 2
  transforms:
    # ä¿®æ”¹paddingä¸ºResizeï¼Œpaddingä»…ä½œå¡«å……ï¼Œå¯¹äºå¤§å›¾ç‰‡æ— æ³•ç¼©æ”¾
    - type: Resize
      target_size: [800, 800]
    - type: Normalize
  # modeåŠ¡å¿…å¯¹åº”ï¼Œå¦åˆ™æ— æ³•ç´¢å¼•æ­£ç¡®çš„è·¯å¾„
  mode: val

# åŸæ•°æ®é›†
# train_dataset:
#   type: PascalVOC
#   dataset_root: data/VOCdevkit/
#   transforms:
#     - type: ResizeStepScaling
#       min_scale_factor: 0.5
#       max_scale_factor: 2.0
#       scale_step_size: 0.25
#     - type: RandomPaddingCrop
#       crop_size: [512, 512]
#     - type: RandomHorizontalFlip
#     - type: RandomDistort
#       brightness_range: 0.4
#       contrast_range: 0.4
#       saturation_range: 0.4
#     - type: Normalize
#   mode: train

# val_dataset:
#   type: PascalVOC
#   dataset_root: data/VOCdevkit/
#   transforms:
#     - type: Padding
#       target_size: [512, 512]
#     - type: Normalize
#   mode: val

# ä»¥ä¸‹å‚æ•°å¯ä»¥åœ¨æ¨¡å‹ymlä¸­è¢«é…ç½®
# ä¼˜åŒ–å™¨é€‰æ‹©
optimizer:
  type: sgd
  momentum: 0.9
  # æ­£åˆ™åŒ–
  weight_decay: 4.0e-5

# å­¦ä¹ ç‡--å¤šé¡¹å¼
learning_rate:
  value: 0.01
  decay:
    type: poly
    power: 0.9
    end_lr: 0.0

# æŸå¤±é…ç½®é¡¹--å¯å‚è€ƒå…¶å®ƒæ¨¡å‹ymlæ–‡ä»¶
loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]
```

**è‡³äºæ¨¡å‹é…ç½®ï¼Œä»¥å½“å‰ä½¿ç”¨Emanetä¸ºä¾‹è¯´æ˜**:

> å¤§å®¶åœ¨ä½¿ç”¨æ¨¡å‹ymlæ—¶ï¼Œä¸ºäº†ä¿è¯æ•°å¯è¯»å–ï¼Œå¯ä»¥ä½¿ç”¨æä¾›çš„ä¸¤ä¸ªæ•°æ®é›†ymlï¼Œåˆ†åˆ«æ“ä½œåŠ è½½ä¸åŒçš„æ•°æ®

```yml
# _base_: '../_base_/pascal_voc12aug.yml'

# ç”¨è°ƒæ•´åçš„pascal_voc2012.ymlæ›¿æ¢åŸå§‹çš„_base_æ•°æ®é›†é…ç½®æ–‡ä»¶
_base_: '../_base_/pascal_voc2012_Deta.yml'

model:
  # æ¨¡å‹åç§°
  type: EMANet
  backbone:
  	  # éª¨å¹²ç½‘ç»œé€‰æ‹©--å¯å‚è€ƒå…¶å®ƒæ¨¡å‹yml
    type: ResNet50_vd
    output_stride: 8
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
  ema_channels: 512
  gc_channels: 256
  num_bases: 64
  stage_num: 3
  momentum: 0.2
  concat_input: True
  # å¤šæŸå¤±
  enable_auxiliary_loss: True
  align_corners: True
  
# æœ€åä¼šæŒ‰ç…§æ¨¡å‹ymlä¸­çš„ä¼˜åŒ–å™¨è¿›è¡Œä¼˜åŒ–
optimizer:
  type: sgd
  momentum: 0.9
  # æ­£åˆ™åŒ–å‚æ•°
  weight_decay: 0.0005

# æœ€åä¼šæŒ‰ç…§æ¨¡å‹ymlä¸­çš„æŸå¤±è¿›è¡Œè®¡ç®—
loss:
  types:
    - type: CrossEntropyLoss
    - type: DiceLoss
  coef: [4.,2.]
```

> å°†é¢„ç½®çš„åŸºçº¿é…ç½®ymlç§»åŠ¨åˆ°ç›¸åº”çš„æ–‡ä»¶å¤¹ä¸‹

* _base_: æ•°æ®åŠ è½½ymlå­˜æ”¾

* emanet: emanetæ¨¡å‹ymlå­˜æ”¾


```python
%cd /home/aistudio/
!cp -u example/pascal_voc2012_Atro.yml PaddleSeg/configs/_base_/
!cp -u example/pascal_voc2012_Deta.yml PaddleSeg/configs/_base_/
!cp -u example/emanet_resnet50_os8_voc12aug_512x512_40k_Deta.yml PaddleSeg/configs/emanet/
!cp -u example/emanet_resnet50_os8_voc12aug_512x512_40k_Atro.yml PaddleSeg/configs/emanet/
```

    /home/aistudio


## 2.å¯åŠ¨è®­ç»ƒ

### 2.1.ä¸‹è½½ä¾èµ–é¡¹

åœ¨å¹³å°ä¸Šå¯ä»¥ä¸ç”¨æ‰§è¡Œï¼Œç¯å¢ƒæ”¯æŒï¼›çº¿ä¸‹å¯èƒ½éœ€è¦ä¸‹è½½ã€‚


```python
# ä¸‹è½½ä¾èµ–é¡¹ï¼Œä¿è¯PaddleSegæ­£å¸¸è¿è¡Œ
%cd PaddleSeg
%pwd
!pip install -r requirements.txt
```

    /home/aistudio/PaddleSeg
    Looking in indexes: https://mirror.baidu.com/pypi/simple/
    Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.21.0)
    Requirement already satisfied: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.26.0)
    Requirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.8.2)
    Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (5.1.2)
    Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2.1.1)
    Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (4.1.1.26)
    Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (4.36.1)
    Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (3.0.12)
    Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.6.3)
    Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.7.2)
    Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.3.4)
    Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (0.10.0)
    Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (2.0.1)
    Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.4.10)
    Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (16.7.9)
    Requirement already satisfied: importlib-metadata; python_version < "3.8" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (0.23)
    Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.15.0)
    Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.3.0)
    Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->-r requirements.txt (line 3)) (0.6.1)
    Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->-r requirements.txt (line 3)) (2.6.0)
    Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->-r requirements.txt (line 3)) (2.2.0)
    Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (1.1.1)
    Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (0.8.53)
    Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (1.0.0)
    Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (2.22.0)
    Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (3.14.0)
    Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (1.20.3)
    Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (0.7.1.1)
    Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (7.1.2)
    Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < "3.8"->pre-commit->-r requirements.txt (line 1)) (0.6.0)
    Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (1.1.0)
    Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (7.0)
    Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (0.16.0)
    Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (2.10.1)
    Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->-r requirements.txt (line 5)) (3.9.9)
    Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->-r requirements.txt (line 5)) (0.18.0)
    Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->-r requirements.txt (line 5)) (2.8.0)
    Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->-r requirements.txt (line 5)) (2019.3)
    Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (2019.9.11)
    Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (2.8)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (1.25.6)
    Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (3.0.4)
    Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < "3.8"->pre-commit->-r requirements.txt (line 1)) (7.2.0)
    Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (1.1.1)


### 2.2. è½½å…¥æ¨¡å‹å¼€å§‹è®­ç»ƒ

> æ›´æ¢è‡ªå®šä¹‰çš„æ¨¡å‹æ–‡ä»¶æ—¶ï¼Œåªéœ€è¦ä¿®æ”¹å¯¹åº”çš„æ¨¡å‹ymlã€æ•°æ®é›†yml(_base_ä¸­çš„yml)ã€ä»¥åŠæ›¿æ¢ä¸‹æ–¹çš„ymlå³å¯è¿›è¡Œè®­ç»ƒäº†

> ä¸è¦æ›´æ”¹è¾“å‡ºç›®å½•ï¼Œå¦åˆ™åè¾¹çš„ä»£ç ä¹Ÿéœ€è¦ä¿®æ”¹ï¼ŒåŒ…æ‹¬é¢„æµ‹ã€åå¤„ç†ä¸­çš„æ‰€æœ‰è·¯å¾„


```python
%cd ~/PaddleSeg
%pwd
# è®­ç»ƒåˆ†å‰²Detachmentçš„æ¨¡å‹ï¼Œå¹¶ä¿å­˜åˆ°/output/Detachment
!python train.py --c configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k_Deta.yml \
--use_vdl \
--save_interval 20 \
--do_eval \
--seed 2021 \
--iters 1000 \
--learning_rate 0.01 \
--save_dir ./output/Detachment

# è®­ç»ƒåˆ†å‰²Atrophyçš„æ¨¡å‹ï¼Œå¹¶ä¿å­˜åˆ°/output/Atrophy
!python train.py --c configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k_Atro.yml \
--use_vdl \
--save_interval 20 \
--do_eval \
--seed 2021 \
--iters 3000 \
--learning_rate 0.01 \
--save_dir ./output/Atrophy
```

    Aborted (core dumped)

## 3.å¼€å§‹é¢„æµ‹

è¿™å¯ä»¥ç›´æ¥ä½¿ç”¨emanetè¿›è¡Œé¢„æµ‹ï¼Œä¸ç”¨ä¿®æ”¹æ•°æ®é›†ymlï¼Œä¹Ÿä¸ç”¨ä¿®æ”¹ç›¸åº”çš„æ¨¡å‹ymlï¼Œæ³¨æ„è®­ç»ƒæƒé‡å¯¹åº”å³å¯ï¼

> é¢„æµ‹ç»“æœæŒ‰ç±»åˆ«åˆ†åˆ«æ”¾åœ¨`./output/result/Detachment` å’Œ `./output/result/Atrophy` ä¸‹

> å¦‚æœä½¿ç”¨ä¸åŒçš„æ¨¡å‹å¯¹ä¸åŒçš„åˆ†å‰²ç±»è¿›è¡Œè®¨è®ºï¼Œæ³¨æ„æ¨¡å‹ymlå³å¯

> æäº¤ç»“æœä¸ºä¸¤ç§å•ç‹¬é¢„æµ‹çš„ç»“æœ

**é»˜è®¤ä½¿ç”¨Iouè¯„ä¼°æœ€å¥½çš„æ¨¡å‹è®­ç»ƒå‚æ•°--best_model**


```python
%cd ~/PaddleSeg/
# é¢„æµ‹Detachment
!python predict.py --config configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k_Deta.yml \
--model_path output/Detachment/best_model/model.pdparams \
--image_path data/Detachment/Test \
--save_dir ./output/result/Detachment

# é¢„æµ‹Atrophy
!python predict.py --config configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k_Atro.yml  \
--model_path output/Atrophy/best_model/model.pdparams \
--image_path data/Atrophy/Test \
--save_dir ./output/result/Atrophy
```

# PaTTAä½¿ç”¨


```python
!pip install PaTTA
```

    Looking in indexes: https://mirror.baidu.com/pypi/simple/
    Collecting PaTTA
      Downloading https://mirror.baidu.com/pypi/packages/72/fa/3a30d550d7fc2a2decce111dbbe890dc14a30a18e3d8df3729aca961b041/patta-0.0.2-py3-none-any.whl
    Installing collected packages: PaTTA
    Successfully installed PaTTA-0.0.2


## 4. ä½¿ç”¨ export.py è„šæœ¬è¿›è¡Œæ¨¡å‹å¯¼å‡º


```python
%cd PaddleSeg/
!python export.py \
       --config  configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k_Deta.yml \
       --model_path output/Detachment/best_model/model.pdparams \
       --save_dir output/emanet

!python export.py \
       --config configs/emanet/emanet_resnet50_os8_voc12aug_512x512_40k_Atro.yml \
       --model_path output/Atrophy/best_model/model.pdparams \
       --save_dir output/atrophy
```

# äº”ã€é¢„æµ‹ç»“æœåå¤„ç†

* å°†ç±»åˆ«å€¼1æ¢ä¸º255ï¼Œè¿›è¡Œèµ›é¢˜ç»“æœæäº¤

## 1. PaTTAå®‰è£…



```python
!git clone https://gitee.com/livingbody/PaTTA.git --depth=1
```

    Cloning into 'PaTTA'...
    remote: Enumerating objects: 30, done.[K
    remote: Counting objects: 100% (30/30), done.[K
    remote: Compressing objects: 100% (25/25), done.[K
    remote: Total 30 (delta 0), reused 25 (delta 0), pack-reused 0[K
    Unpacking objects: 100% (30/30), done.
    Checking connectivity... done.



```python
%cd ~
import glob
path = glob.glob('/home/aistudio/Lesion_Segmentation/Detachment/*')
f = open('de_test.txt', 'w')
for i in path:
    f.write(i+'\n')
f.close()
```

    /home/aistudio



```python
%cd ~
import glob
path = glob.glob('/home/aistudio/Lesion_Segmentation/Atrophy/*')
f = open('at_test.txt', 'w')
for i in path:
    f.write(i+'\n')
f.close()
```

    /home/aistudio


## 2.å°†ç±»åˆ«å€¼1æ¢ä¸º255


```python
%cd /home/aistudio/
!python utils/post_process.py
```

    /home/aistudio
    â€”â€”â€”â€”å¼€å§‹æäº¤ç»“æœå‰çš„åå¤„ç†â€”â€”â€”â€”
    â€”â€”â€”â€”å¼€å§‹Detachmenté¢„æµ‹ç»“æœåå¤„ç†â€”â€”â€”â€”
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:24<00:00, 16.09it/s]
    â€”â€”â€”â€”å¼€å§‹Atrophyé¢„æµ‹ç»“æœåå¤„ç†â€”â€”â€”â€”
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:24<00:00, 16.44it/s]
    åå¤„ç†å®Œæˆ(cost: 49.602564334869385 s)ï¼


## 3.PaTTAæˆç»©æå‡


```python
%cd ~/PaddleSeg/

!python PaTTA/tools/seg.py --model_path='output/emanet/model' \
                 --batch_size=16 \
                 --test_dataset='/home/aistudio/de_test.txt'
```


```python
%cd ~/PaddleSeg/
!mkdir result
!python PaTTA/tools/seg.py --model_path='output/atrophy/model' \
                 --batch_size=16 \
                 --test_dataset='/home/aistudio/at_test.txt'
```

# å…­ã€æäº¤æ¯”èµ›ç»“æœ

## 1.æäº¤æ–‡ä»¶æ•´ç†


```python
# å¤åˆ¶æ–‡ä»¶åˆ°æœ€é¡¶å±‚ç›®å½•
%cd /home/aistudio
!cp -r PaddleSeg/output/result/ Lesion_Segmentation

# è¿‡ç¨‹ç§»åŠ¨æ–‡ä»¶--ä¿è¯ä¸åŒ…å«ç”Ÿæˆçš„å­ç›®å½•
%cd Lesion_Segmentation
!cp -r Detachment/pseudo_color_prediction/. Detachment
!cp -r Atrophy/pseudo_color_prediction/. Atrophy

# è·å–æŒ‡å®šçš„æäº¤ç›®å½•æ ¼å¼
!rm -rf Detachment/added_prediction
!rm -rf Detachment/pseudo_color_prediction

!rm -rf Atrophy/added_prediction
!rm -rf Atrophy/pseudo_color_prediction
```

    /home/aistudio
    /home/aistudio/Lesion_Segmentation


## 2.æäº¤æ–‡ä»¶æ‰“åŒ…


```python
# å‹ç¼©æ–‡ä»¶
%cd /home/aistudio
!zip -r Lesion_Segmentation.zip Lesion_Segmentation
```

# ä¸ƒã€å…¶å®ƒå»ºè®®


* 1. æ¨¡å‹å»ºè®®ï¼šæ³¨æ„åŠ›æ¨¡å‹(EMANetç­‰)æˆ–è€…è°ƒæ•´unetæ¨¡å‹
* 2. æŸå¤±å»ºè®®ï¼šå¤šæŸå¤±ç»“æ„ï¼Œä¸åŒçš„coefï¼Œé’ˆå¯¹èµ›é¢˜çš„ç‰¹æ®ŠæŸå¤±ç­‰(Diceç­‰)
* 3. æ¨¡å‹é­”æ”¹å»ºè®®ï¼šå°è¯•å¯¹Unetæ·»åŠ æ³¨æ„åŠ›æ¨¡å—ï¼Œä¿®æ”¹å‚æ•°ï¼Œæˆ–è€…è°ƒæ•´ä¸åŒçš„backboneä¸indicesç»„åˆ
* 4. ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡ç­–ç•¥çš„è°ƒæ•´
* 5. åˆ†å‰²ä»»åŠ¡PaTTAå¯ä»¥å¤šå¤šå°è¯•

# å…«ã€é™„ä»¶

## 1.notebookä»£ç 

[javaroom.ipynb](javaroom.ipynb)

## 2.Atrophy_best_model.zipæ¨¡å‹

[Atrophy_best_model.zip](Atrophy_best_model.zip)

## 3.Detachment_best_model.zipæ¨¡å‹

[Detachment_best_model.zip](Detachment_best_model.zip)

